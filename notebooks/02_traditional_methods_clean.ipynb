{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Traffic Sign Detection - Traditional Methods\n\nThis notebook implements and evaluates traditional computer vision approaches:\n1. HOG + SVM\n2. Color + Shape Detection\n\n**Note**: Traditional methods work well on CPU, no GPU needed."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Setup environment (same as data exploration)\nimport sys\nIN_COLAB = 'google.colab' in sys.modules\n\nif IN_COLAB:\n    !git clone https://github.com/YOUR_USERNAME/traffic-sign-detection.git\n    %cd traffic-sign-detection\nelse:\n    import os\n    if os.path.basename(os.getcwd()) == 'notebooks':\n        os.chdir('..')\n\n!pip install -q scikit-learn scikit-image opencv-python matplotlib seaborn joblib tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\nsys.path.append('src')\n\nimport numpy as np\nimport cv2\nimport matplotlib.pyplot as plt\nfrom pathlib import Path\nfrom tqdm import tqdm\nimport time\n\nfrom src.traditional.hog_svm.detector import HOGSVMDetector, SlidingWindowDetector\nfrom src.traditional.color_shape.detector import ColorShapeDetector, SignColor\nfrom src.utils.metrics import DetectionMetrics, SpeedMetrics\nfrom src.utils.visualization import BoundingBoxVisualizer, ResultVisualizer\n\nprint(\"Libraries imported successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Load Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load dataset info\nimport yaml\n\ndata_yaml_path = 'data/raw/yolov8/data.yaml'\n\nwith open(data_yaml_path, 'r') as f:\n    data_config = yaml.safe_load(f)\n\nclass_names = data_config['names']\nnum_classes = data_config['nc']\n\nprint(f\"Number of classes: {num_classes}\")\nprint(f\"Classes: {class_names}\")\n\n# Get image paths\ndata_root = Path('data/raw/yolov8')\ntrain_images = sorted(list((data_root / 'train' / 'images').glob('*.*')))\nval_images = sorted(list((data_root / 'valid' / 'images').glob('*.*')))\n\nprint(f\"\\nTrain images: {len(train_images)}\")\nprint(f\"Val images: {len(val_images)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.1 Helper Functions for Detection Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_yolo_annotations(label_path, img_width, img_height):\n    \"\"\"\n    Load YOLO format annotations and convert to [x1, y1, x2, y2] format\n    \n    Args:\n        label_path: Path to YOLO label file\n        img_width: Image width in pixels\n        img_height: Image height in pixels\n        \n    Returns:\n        boxes: numpy array of boxes [N, 4] in (x1, y1, x2, y2) format\n        classes: numpy array of class IDs [N]\n    \"\"\"\n    boxes = []\n    classes = []\n    \n    if not label_path.exists():\n        return np.array([]), np.array([])\n    \n    with open(label_path, 'r') as f:\n        for line in f:\n            parts = line.strip().split()\n            if len(parts) < 5:\n                continue\n                \n            class_id = int(parts[0])\n            cx, cy, w, h = map(float, parts[1:5])\n            \n            # Convert from YOLO format (normalized cx, cy, w, h) to pixel coordinates (x1, y1, x2, y2)\n            x1 = int((cx - w/2) * img_width)\n            y1 = int((cy - h/2) * img_height)\n            x2 = int((cx + w/2) * img_width)\n            y2 = int((cy + h/2) * img_height)\n            \n            # Clip to image boundaries\n            x1 = max(0, min(x1, img_width - 1))\n            y1 = max(0, min(y1, img_height - 1))\n            x2 = max(0, min(x2, img_width - 1))\n            y2 = max(0, min(y2, img_height - 1))\n            \n            # Only add valid boxes\n            if x2 > x1 and y2 > y1:\n                boxes.append([x1, y1, x2, y2])\n                classes.append(class_id)\n    \n    return np.array(boxes), np.array(classes)\n\nprint(\"Helper functions defined successfully!\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}